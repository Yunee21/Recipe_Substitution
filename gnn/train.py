import random
import pickle
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric
import torch_geometric.transforms as T
from torch.utils.data import random_split
from torch_geometric.data import HeteroData, DataLoader
from torch_geometric.nn import HANConv

from tqdm import tqdm

from lib import utils as uts
from gnn.gnn_utils import maskIngredientNode, padIngredientNode, generateMaskedVariants
from gnn.model import ConditionalHeteroGraphVAE
from gnn.loss import lossFunction, classification_loss
from torch.nn.functional import cosine_embedding_loss


def train(dataloader, max_num_of_ingre, model, optimizer, device, accumulation_steps=1, beta=1.0):
    model.train()
    total_loss = 0
    total_recon_loss = 0
    total_kl_loss = 0

    for i, data in enumerate(dataloader):
        data = data.to(device)
        '''
        # original ingredient feature -> target
        target_ingre_feat = data['ingredient'].x.clone()

        pad_size = max_num_of_ingre - target_ingre_feat.size(0)
        pad_feat = torch.zeros(pad_size, target_ingre_feat.size(1), device=device)
        target_ingre_feat = torch.cat([target_ingre_feat, pad_feat], dim=0)

        # random sampling for masking in a recipe
        mask_id, orig_feat, data = maskIngredientNode(data)

        # padding
        data = padIngredientNode(data, max_num_of_ingre)
        '''
        # ê° ì¬ë£Œë¥¼ ë§ˆìŠ¤í‚¹í•œ ë ˆì‹œí”¼ variant ìƒì„±
        variants = generateMaskedVariants(data)

        for mask_id, masked_name, orig_feat, variant in variants:
            # padding
            variant = padIngredientNode(variant, max_num_of_ingre)
            data = variant.clone()

            #recon_ingre, mu, logvar = model(data) # regression

            recon, mu, logvar = model(data) # regression
            target = orig_feat.to(device)

            recon = recon.squeeze(0)

            if torch.norm(recon) == 0 or torch.norm(target) == 0:
                print("ğŸš¨ Zero vector detected before normalization")


            cosine_loss = F.cosine_embedding_loss(
                recon.unsqueeze(0),      # [1, 100]
                target.unsqueeze(0),     # [1, 100]
                torch.tensor([1.], device=device)  # label: positive pair
            )
            #recon_loss = F.mse_loss(recon, target)
            recon_loss = F.smooth_l1_loss(recon, target, reduction='sum')
            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
            #loss = recon_loss + beta * kl_loss + cosine_loss
            loss = recon_loss + beta * kl_loss

            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            total_recon_loss += recon_loss.item()
            total_kl_loss += kl_loss.item()

        '''
        # compute loss only for masking node in regression
        _, recon_loss, kl_loss = lossFunction(recon_ingre, target_ingre_feat, mu, logvar, data['ingredient'].mask)

        # Warm-upì„ ìœ„í•´ KL í•­ì— betaë¥¼ ê³±í•´ ìƒˆë¡œ ì •ì˜í•œ loss
        loss = recon_loss + beta * kl_loss

        # --- Gradient Accumulation í•µì‹¬ ---
        # ë³´í†µ, accumulation ì‹œì—ëŠ” ê° stepì˜ lossë¥¼ accumulation_stepsë¡œ ë‚˜ëˆ„ì–´ backwardí•©ë‹ˆë‹¤.
        # ê·¸ë˜ì•¼ gradientê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šê³ , ì‹¤ì œë¡œ batch_size=4ë¡œ ì²˜ë¦¬í•œ ê²ƒê³¼ ìœ ì‚¬í•´ì§‘ë‹ˆë‹¤.
        loss = loss / accumulation_steps
        loss.backward()

        # gradientë¥¼ ëª‡ ë²ˆ ìŒ“ì•˜ëŠ”ì§€ ì„¸ê³ ,
        # ì •í•´ì§„ accumulation_stepsì— ë„ë‹¬í•˜ë©´ í•œ ë²ˆ optimizer.step().
        if (i + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()

        # í†µê³„ìš©
        total_loss += loss.item() * accumulation_steps  # ì‹¤ì œ ìŠ¤ì¼€ì¼(ê³±ì…ˆ í•´ì œ)
        total_recon_loss += recon_loss.item()
        total_kl_loss += kl_loss.item()

    # ë§Œì•½ ë°ì´í„° ê°œìˆ˜ê°€ accumulation_stepsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠëŠ” ê²½ìš°,
    # ë£¨í”„ê°€ ëë‚œ ë’¤ ë‚¨ì•„ ìˆëŠ” gradientë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ step()í•  í•„ìš”ê°€ ìˆì„ ìˆ˜ ìˆìŒ.
    # (ê¸°ë³¸ ì˜ˆì‹œëŠ” ìƒëµ, í•„ìš”í•˜ë©´ ì•„ë˜ì²˜ëŸ¼ ì²˜ë¦¬)
    remainder = len(dataloader) % accumulation_steps
    if remainder != 0:
        optimizer.step()
        optimizer.zero_grad()
    '''

    avg_loss = total_loss / len(dataloader)
    avg_recon_loss = total_recon_loss / len(dataloader)
    avg_kl_loss = total_kl_loss / len(dataloader)
    #print(f"Average Loss: {avg_loss:.4f}, Recon Loss: {avg_recon_loss:.4f}, KL Loss: {avg_kl_loss:.4f}")
    return avg_loss, avg_recon_loss, avg_kl_loss

def validate(dataloader, max_num_of_ingre, model, device):
    model.eval()
    total_loss = 0
    total_recon_loss = 0
    total_kl_loss = 0

    with torch.no_grad():
        for data in dataloader:
            data = data.to(device)
            '''
            target_ingre_feat = data['ingredient'].x.clone()

            pad_size = max_num_of_ingre - target_ingre_feat.size(0)
            pad_feat = torch.zeros(pad_size, target_ingre_feat.size(1), device=device)
            target_ingre_feat = torch.cat([target_ingre_feat, pad_feat], dim=0)

            # also do masking in validation (í˜¹ì€ masking ì—†ì´ ì „ì²´ ì¬êµ¬ì„±ì„ í‰ê°€í•  ìˆ˜ë„ ìˆìŒ)
            mask_id, orig_feat, data = maskIngredientNode(data)

            # padding
            data = padIngredientNode(data, max_num_of_ingre)
            '''
            variants = generateMaskedVariants(data)

            for mask_id, masked_name, orig_feat, variant in variants:
                data = variant.clone()

                recon, mu, logvar = model(data) # regression
                target = orig_feat.to(device)
                recon = recon.squeeze(0)

                cosine_loss = F.cosine_embedding_loss(
                    recon.unsqueeze(0),      # [1, 100]
                    target.unsqueeze(0),     # [1, 100]
                    torch.tensor([1.], device=device)  # label: positive pair
                )
                #recon_loss = F.mse_loss(recon, target)
                recon_loss = F.smooth_l1_loss(recon, target, reduction='sum')
                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                loss = recon_loss + kl_loss + cosine_loss


                total_loss += loss.item()
                total_recon_loss += recon_loss.item()
                total_kl_loss += kl_loss.item()
                '''

                recon_ingre, mu, logvar = model(data)

                loss, recon_loss, kl_loss = lossFunction(recon_ingre, target_ingre_feat, mu, logvar, data['ingredient'].mask)
                total_loss += loss.item()
                total_recon_loss += recon_loss.item()
                total_kl_loss += kl_loss.item()
                '''

    avg_loss = total_loss / len(dataloader)
    avg_recon_loss = total_recon_loss / len(dataloader)
    avg_kl_loss = total_kl_loss / len(dataloader)
    return avg_loss, avg_recon_loss, avg_kl_loss


def run(recipe_graphs, hidden_dim=64, latent_dim=32, heads=1, dropout=0.0, num_epochs=20, batch_size=1, accumulation_steps=4, lr=1e-3):

    device = torch_geometric.device('auto')
    print(f"Device: {device}")

    # ê¸°ì¡´ recipe_graphs ë¦¬ìŠ¤íŠ¸ì—ì„œ direction ë…¸ë“œê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§ (loss = nan ì„ ë°©ì§€
    filtered_recipe_graphs = [data for data in recipe_graphs if data['direction'].x.size(0) > 0]
    assert len(recipe_graphs) == len(filtered_recipe_graphs)

    # *** Padding ***
    max_num_of_ingre = max([data['ingredient'].x.size(0) for data in recipe_graphs])
    print(f"ëª¨ë“  ë ˆì‹œí”¼ ì¤‘ì—ì„œ ingredient ê°œìˆ˜ê°€ ê°€ì¥ ë§ì„ ë•ŒëŠ” {max_num_of_ingre}ê°œ ì…ë‹ˆë‹¤.")

    #recipe_graphs_with_padding = [padIngredientNode(data, max_num_ingre) for data in recipe_graphs]
    #print(recipe_graphs_with_padding[0])
    #print(recipe_graphs_with_padding[0]['ingredient'].x)

    # ì „ì²´ ë°ì´í„°ì…‹ ë¶„í•  (70% train, 30% validation)
    dataset_size = len(recipe_graphs)
    train_size = int(0.8 * dataset_size)
    val_size = dataset_size - train_size
    train_dataset, val_dataset = random_split(recipe_graphs, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    metadata = recipe_graphs[0].metadata()
    print(f"metadata: {metadata}")

    # hyperparameter
    ingre_feat_dim = recipe_graphs[0]['ingredient'].x.shape[1]
    direc_feat_dim = recipe_graphs[0]['direction'].x.shape[1]
    cond_dim = len(recipe_graphs[0].nutrition_label)
    ingre_out_dim = ingre_feat_dim
    #num_of_ingre = recipe_graphs[0]['ingredient'].x.size(0)  # ê° ë ˆì‹œí”¼ì˜ ingredient ìˆ˜ (íŒ¨ë”©ëœ ê°’)
    num_of_ingre = max_num_of_ingre

    model = ConditionalHeteroGraphVAE(ingre_feat_dim, direc_feat_dim, hidden_dim, latent_dim, cond_dim, ingre_out_dim, num_of_ingre, metadata, heads=heads, dropout=dropout)
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)

    best_val_loss = float('inf')
    for epoch in range(1, num_epochs + 1):
        beta = min(1.0, (epoch / 10.0))
        train_loss, train_recon_loss, train_kl_loss = train(train_loader, max_num_of_ingre, model, optimizer, device, accumulation_steps, beta)
        val_loss, val_recon_loss, val_kl_loss = validate(val_loader, max_num_of_ingre, model, device)
        print(f"Epoch {epoch}/{num_epochs} - Train Loss: [total: {train_loss:.4f}, recon: {train_recon_loss:.4f}, kl: {train_kl_loss:.4f}]")
        print(f"             - Val Loss:   [total: {val_loss:.4f}, recon: {val_recon_loss:.4f}, kl: {val_kl_loss:.4f}]")
        #print(f"Epoch {epoch}/{num_epochs} - Train Loss: [total: [{train_loss:.4f}], recon: [{train_recon_loss:.4f}], kl: [{train_kl_loss:.4f}],
        #                                       Val Loss: [total: [{val_loss:.4f}], recon: [{val_recon_loss:.4f}], kl: [{val_recon_loss:.4f}]")
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "best_model.pt")

    print("Training complete. Best validation loss:", best_val_loss)


def main():
    seed = 721
    random.seed(721)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    # *** Load data ***
    recipe_graphs = uts.loadPickle("gnn/results/recipe_graphs_lst.pkl")
    #recipe_graphs = DataLoader(recipe_graphs_lst, batch_size=1, shuffle=True)
    '''
    # *** Padding ***
    max_num_ingre = max([data['ingredient'].x.size(0) for data in recipe_graphs])
    print(f"ëª¨ë“  ë ˆì‹œí”¼ ì¤‘ì—ì„œ ingredient ê°œìˆ˜ê°€ ê°€ì¥ ë§ì„ ë•ŒëŠ” {max_num_ingre}ê°œ ì…ë‹ˆë‹¤.")

    recipe_graphs_with_padding = [padIngredientNode(data, max_num_ingre) for data in recipe_graphs]
    print(recipe_graphs_with_padding[0])
    print(recipe_graphs_with_padding[0]['ingredient'].x)
    '''
    run(recipe_graphs,
        hidden_dim=128,
        latent_dim=32,
        heads=4,
        dropout=0.5,
        num_epochs=50,
        batch_size=1,
        accumulation_steps=1,
        lr=1e-6
    )


if __name__ == "__main__":
    main()
